
[section User's Guide]
[split-section]
[output-in-subdirectory]


[#^ RError reference.Reply.members.Error]

This user's guide is an in-depth introduction to parsing with FParsec. It explains how `Parser` functions work, covers the most important parser combinators in detail, explains how you can customize error messages, and discusses some important practical aspects of parser writing, such as debugging and performance optimizations.

The aim of this user's guide is to prepare you for writing "real world" parser applications with FParsec. It doesn't try to cover every feature of the library, but focuses on covering the core concepts such that you can gain a deep understanding of the library design.

Although there is some overlap between the @tutorial@ and this user's guide, it's probably a good idea to read the tutorial first, since it will give you a quick overview of the library that will later help you put things into perspective. You might also want to experiment with some small parsers before you start reading the user's guide, or maybe in parallel to reading it, so that it becomes easier for you to relate the dry technical discussions to exciting practical applications ☺

The first seven chapters of this user's guide build on each other. The remaining chapters are rather independent and can be read in any order.

[section Parser functions]

An FParsec parser is a function that reads input from a text stream. When it succeeds, it returns a result value (e.g. a parsed number or an [url "http://en.wikipedia.org/wiki/Abstract_syntax_tree" AST] node); when it fails, it returns error messages describing what went wrong.

The following type abbreviation from the `Primitives` module defines the basic type of parser function supported throughout the FParsec library:
``type Parser<'Result,'UserState> = CharStream<'UserState> -> Reply<'Result>``

As you can see from this definition, parser functions only accept a single argument: a `CharStream<'UserState>` instance. The `CharStream` class is FParsec's specialized stream type for "text" streams, i.e. streams of Unicode chars. A `CharStream` can either be created directly from a string or it can be created from  a file path or `System.IO.Stream`. In the latter cases the `CharStream` will take care of decoding the binary input into UTF-16 chars, similar to what a `System.IO.StreamReader` does. What separates `CharStream` from the `StreamReader` and similar classes is that it comes with some advanced features that make it especially suitable for backtracking parser applications.

We will discuss the purpose of the `'UserState` type in more detail in later chapters. For now it's enough to note that the user state is a user-definable component of the `CharStream` state. If you don't need a user state, you will normally define `'UserState` to be `unit`. To save some key strokes and screen real estate, we usually abbreviate `'UserState` as `'u`.

The `Reply<'Result>` value returned from a parser function is a a simple value type container for the parser result and possible error messages. It contains a status field indicating whether the parser succeeded or not, a field for the result value (of type `'Result`) and a field with a possibly empty list of error messages. We will explain these fields in more details in [^internals-of-a-simple-parser-function].

A very basic example of a parser is the `asciiLower` parser from the `CharParsers` module:
``val asciiLower: Parser<char,'u>``
It parses any lower case ASCII char, i.e. any char in the range `'a'` - `'z'`, and, if successful, returns the parsed char as part of its reply.

Many predefined parsers expect one or more parameter values as arguments. Take for instance the `skipString` function:
``val skipString: string -> Parser<unit,'u>``
It takes a string as an argument and returns a parser that skips over this (and only this) string in the input.

[note
Implementing parser grammars with FParsec usually means composing parsers for higher-level grammar rules from parsers for lower-level rules. You start with simple parsers for the leaf nodes of your grammar and then work your way up step-by-step until you eventually obtain a parser for the complete grammar. The simple representation of parsers as functions makes this composition particularly easy and allows for a straightforward and intuitive implementation of the library primitives.
]

[/section]

[section Running parsers on input]

While it is not difficult to construct a `CharStream` instance yourself, then apply a parser function to the `CharStream`, then interpret the returned `Reply` value and finally dispose the `CharStream` again, it takes less effort to instead use one of the several @`runParser...` functions@ from the `CharParsers` module.

Among the `runParser...` functions `run` is the most convenient for simple testing purposes:
``val @run@: Parser<'a, unit> -> string -> ParserResult<'a,unit>``

`run` applies the parser given as the first argument to a `CharStream` constructed from the string argument and then captures the return value as `ParserResult` value. The `ParserResult` type is a simple discriminated union that is a bit more convenient to interpret than the `Reply` values returned by `Parser` functions.

For example:
``{fsi}
> run pint32 "0xff";;
val it : ParserResult<int32,unit> = Success: 255

> run pint32 "0xgf";;
val it : ParserResult<int32,unit> = Failure:
Error in Ln: 1 Col: 3
0xgf
  ^
Expecting: hexadecimal digit
``

The text messages displayed in these examples after the `=` signs are the default string representations of the returned `ParserResult` values, just like they are printed in the [@ F# Interactive] console. The reference documentation describes the two union cases `Success` and `Failure` of the `ParserResult` type in more detail.

`run` only supports parser functions with no user state, i.e. with a `unit` user state. If you want to test parsers that depend on a user state, you will need to use one of the other `runParser...` functions, e.g. `runParserOnString`. Please see the reference for more details on the @`runParser...` functions@.

Note that the `runParser...` functions are primarily meant for the "end-users" of parsers, i.e. those users that apply an aggregate parser on the content of a complete input stream. This is a situation different from the one where you implement a `Parser` function yourself. In the latter case you typically work directly with the input `CharStream` and output `Reply` values.

[/section]


[section Internals of a simple `Parser` function]

In the beginning of this user's guide we noted that `asciiLower` "parses" a lower case ASCII char and that `skipString` "skips" over a string, but we haven't yet explained what it actually means for a `Parser` function to "parse" a letter or "skip" a string. That's what we will do in this chapter. To explain how `Parser` functions work, we will discuss the implementation of a simple string parser. This also gives us the opportunity to explain some important details about the `Reply` and `CharStream` types.

[section The code]
The parser whose implementation we will discuss in this chapter is
``
val stringReturn: string -> 'a -> Parser<'a,'u>
``

Like `skipString str` the parser `stringReturn str result` skips over the string `str`, but it returns `result` as part of its reply value, instead of the `unit` value `()` that `skipString str` returns. This makes `stringReturn` a bit more general than `skipString`. Indeed, the two library parsers `pstring` and `skipString` are actually implemented with the help of `stringReturn`. For example, `skipString str` is defined as `stringReturn str ()`.

A simplified version[fn The library version is a bit more complicated because it contains optimized paths for argument strings with only 1 or 2 chars.] of the actual implementation of `stringReturn` in the library is
``
let [no-auto-link stringReturn] str result : Parser<_,_> =                                // 1
    checkStringContainsNoNewlineChar str "pstring/skipString/stringReturn" // 2
    let error = expectedString str                                         // 3
    fun stream ->                                                          // 4
        if stream.Skip(str) then                                           // 5
            Reply(result)                                                  // 6
        else                                                               // 7
            Reply(Error, error)                                            // 8
``

Let's start with the general structure of this implementation: We define a function [no-auto-link `stringReturn`] with two parameters that returns a function closure. The type annotation `: Parser<_,_>` on /line 1/ fixes the type of the returned function closure to `Parser<'a,'u>` and in particular constrains the type of its argument to `CharStream<'u>`. Remember, the type `Parser<'a,'u>` is simply an abbreviation for `CharStream<'u> -> Reply<'a>`, where `'a` represents the result type and `'u` the user state type.

Implementing our parameterized parser as a function returning a parser closure allows us to factor out common setup work that only needs to be done once for every parser.[fn Even parsers without a parameter, like e.g. `asciiLower`, are actually compiled as properties returning a new function object every time they are called. This is because the user state type variable makes `asciiLower` generic, while function values can only have a non-generic type.] In this case we only need to check once (/line 2/) whether the string contains a newline char, i.e. `'\r'` or `'\n'`, (we'll explain below why this is necessary) and in /line 3/ we preconstruct the error message that is later used whenever the parser is applied and doesn't find `str` in the input (we'll write more about error messages in later chapters).

The actual parsing logic is completely straightforward: On /line 5/ the parser calls the CharStream's `Skip` method with the argument `str`. If the next chars in the stream match `str`, `Skip` advances the stream's position by the length of the passed string and returns `true`; otherwise, it doesn't change the position of the stream and returns `false`. Thus, if the string is skipped, the parser returns with a `Reply` value containing the result (/line 6/). Otherwise, it returns a `Reply` with the preconstructed error message (/line 8/).

[/section]

[section The `Reply` type]

This is a good time to discuss the `Reply` type in a little more detail.

``
type Reply<'TResult> = struct
  new: 'TResult -> Reply<'TResult>
  new: ReplyStatus * ErrorMessageList -> Reply<'TResult>
  new: ReplyStatus * 'TResult * ErrorMessageList -> Reply<'TResult>

  val mutable Status: ReplyStatus
  /// If Status <> Ok then the Result value is undefined and may be null.
  val mutable Result: 'TResult
  val mutable Error: ErrorMessageList
end
``

Similar to a tuple, a `Reply` can be seen as an aggregate of it three fields: `Status`, `Result` and [no-auto-link `Error`]. The `Status` field contains a `ReplyStatus` enum value indicating whether the parser succeeded (`Ok`) or failed (`Error` or `FatalError`). By returning a `FatalError` instead of an `Error` a parser can signal that no error recovery should be tried (except through backtracking mechanisms, which we explain later). If the `Status` is `Ok`, the `Result` field contains the parser result; otherwise, its value is undefined (and `null`). The `Error` field holds a list of error messages in the form of an `ErrorMessageList` value. An empty `ErrorMessageList` is represented as a `null` value.

The 1-argument constructor we use in /line 6/ sets the status to `Ok` and the result value to `result`. The 2-argument constructor we use in /line 8/ sets the status to `Error` and the error message to `error`. The `Reply` type also defines a 3-argument constructor, which  simply sets the fields to the respective argument values. The default valuetype constructor with 0 arguments initializes the `Reply` value to `Reply(Error, null)`.

The error messages returned in the `Reply` value implicitly refer to the current stream position. Since the `ErrorMessage` values stored in the `ErrorMessageList` do not themselves contain an error position, they can only be interpreted together with the position of the `CharStream` as it is when the parser returns.

[/section]

[section The parser state and the line and column count]

Usually one `CharStream<'u>` instance is created per input file and all parser functions involved in parsing elements of the same file are passed the same `CharStream` instance. Since calling the methods of a `CharStream` may change its state, parser functions have to be careful about when and how they change the `CharStream` state, because it obviously may affect all parsers subsequently called.

In the example above, `stringReturn` only advances the stream position when it succeeds. This makes it an *atomic* string parser, because it does not consume input if only the beginning of the argument string matches the input. Whether or not a parser consumes input before it fails has important implications for the error handling, as we will discuss later in this user's guide.

Except for the freely customizable `UserState`, all the mutable state information in the `CharStream<'u>` instance pertains to the location of the next char in the text stream. The most important element of the state is the char `Index`, which uniquely identifies the UTF-16 char in the stream. In addition to the index of the next char, the `CharStream` also keeps track of char's `Line` number and the index of the first char in the line, the `LineBegin`. By combining the `Index` and `LineBegin` we can calculate a `Column`. The `CharStream`'s `Name` serves as a description or identifier for the stream.

Only the char index is strictly necessary for the core stream functionality. We also store the other pieces of state information in a `CharStream<'u>` instance because having all parser state information in one place reduces complexity and allows us to expose a more convenient API to `Parser` functions.

[note The `CharStream<'u>.State` property returns a snapshot of all the mutable state components in the form of a `CharStreamState<'u>` value.

The state information that is exposed through the `CharStream<'u>.State` property is *all* the state that is tracked by `FParsec` parsers, which is why we also refer to it as *the parser state*.[fn Strictly speaking, a `CharStream<'a>` instance has a little more publically observable mutable state than the one that is also exposed through the `State` property. For example, the `MinRegexSpace` configuration parameter is not tracked in the `State` parameter. Another example is the value of the `IndexOfLastCharPlus1` property which changes once the last char of the stream is detected. However, there shouldn't be a reason that a parser needs to restore the old values of these properties upon backtracking, so we just treat these properties as constant and ignore them when we discuss the mutable `CharStream` state.]
]

Ideally, the `CharStream` class would keep track of the column and line count in a completely automated fashion. Ideally, the `CharStream` class would give the user a way to freely specify the recognized set of newline character sequences and all `CharStream` methods then would automatically detect such newlines in the input. Unfortunately, such a configuration option would be difficult to implement efficiently and would likely have a severe impact on performance (at least in comparison to the hard-coded alternative, and with the current language and compiler support).

Since the `CharStream` can't provide automatic support for all possible notions of a newline, it exposes two sets of methods in its interface. One set provides the basic stream operations, such as skipping a certain number of UTF-16 chars or matching a string with the stream content. These methods come without any automatic newline detection, but they offer optimal performance and give the user complete freedom to manually register any kind of newline. The other set of methods provides some frequently needed higher-level text operations, such as skipping over a sequence of whitespace chars or reading a sequence of chars satisfying a given predicate function. These other methods automatically detect any of the 3 standard newline char sequences `"\n"`, `"\r\n"` and `"\r"`, because that's the notion of a newline used by most text applications. In combination both sets of methods cover the needs of a majority of text parsers in a convenient and efficient manner.

[note Maybe you wonder why we don't just leave the line and column count completely to the user instead of complicating the `CharStream` API. The reason we keep track of a line count in the `CharStream` class is that most non-trivial text-parsing applications require a line count for error reporting purposes. Implementing it at a relatively low API level brings significant performance advantages and relieves higher-level API users from constantly having to code around the special case of newline chars.]

If you have a look at the reference documentation for `CharStream`, you'll see that the `CharStream` methods that automatically detect newlines are easily discernible by their name. The `Skip` method we used in the above example does *not* belong to these methods, which is why we have to make sure in /line 2/ that the string doen't contain any newlines. In practice one hardly ever uses a parser like `stringReturn` with a string containing a newline, hence lifting this restriction wouldn't be worth the effort, especially since simple workarounds are available.[fn For example, `stringReturn "str1\nstr2" result` can be replaced with `attempt (skipString "str1" >>. newline >>. stringReturn "str2" result)`.]
[/section]

[/section]
[section Applying parsers in sequence]


Now that we have discussed how `Parser` functions work, we can start explaining how FParsec's parser combinators work.

In this chapter we will discuss combinators that allow you to apply multiple parsers in sequence, i.e. parse the beginning of the input with the first parser, then parse the following input with the second parser, and so on.

[section The definition of `>>.`]

The simplest combinators for sequentially applying two parsers are
``
val (>>.):   Parser<'a,'u> -> Parser<'b,'u> -> Parser<'b,'u>
val (.>>):   Parser<'a,'u> -> Parser<'b,'u> -> Parser<'a,'u>
``

Both operators take two parsers as arguments and return a combined parser that applies the two parsers in sequence. As you can infer from the type signatures, `p1 >>. p2` returns the result of `p2` and `p1 .>> p2` the result of `p1`. In each case the point points to the parser whose result is returned.

In order to explain exactly what it means to apply two parser in sequence, we give a full definition of the `>>.` operator:
``
let [no-auto-link (>>.)] (p1: Parser<'a,'u>) (p2: Parser<'b,'u>) =
    fun stream ->
        let reply1 = p1 stream
        if reply1.Status = Ok then
            let stateTag = stream.StateTag
            let mutable reply2 = p2 stream
            if stateTag = stream.StateTag then                        // (1)
                reply2.[^RError Error] <- mergeErrors reply1.[^RError Error] reply2.[^RError Error] // (2)
            reply2
        else // reconstruct error reply with new result type
            Reply(reply1.Status, reply1.[^RError Error])
``

The implementation of `p1 >>. p2` should be quite self-explanatory: First `p1` is applied to the input `stream`. If `p1` succeeds, i.e. if the status of `reply1` is `Ok`, `p2` is applied to stream and the reply of `p2` then becomes the reply of the combined parser. However, if `p1` fails, its reply is immediately propagated as the reply of the combined parser. Since `reply1` has type `Reply<'a,'u>` but `p1 >>. p2` needs to return a `Reply<'b,'u>`, the error reply needs to be reconstructed with a new result type before it can be returned.
[/section]

[section Merging error messages]

We mentioned earlier that the error messages returned in the `Reply.[^RError Error]` field implicitly refer to the state of the `CharStream` at the time the parser returns. In particular the error messages refer to the then current *stream position*. Since the messages do not contain themselves a separate record of the error position they can only be interpreted together with the `CharStream` state.

When `p2` does not change the parser state, the error messages from both replies refer to the state of the `CharStream` as it is when
`p1 >>. p2` returns. Thus, the combinator needs to merge the (immutable) `ErrorMessageList`s from both replies, so that the returned list contains all the relevant error messages (see the line marked with `(2)`).

In order to check whether the `CharStream` state has changed, the combinator does not compare the full states from before and after `p2` is invoked. Instead it only compares the `StateTag` values (see line `(1)`). This improves performance and --- for most practical purpose --- is almost equivalent to comparing the full state, as we will discuss below.

[note The way `[no-auto-link (>>.)]` handles errors and merges error messages is a template for all combinators in FParsec that perform multiple sequential parser invocations.]

You may wonder why the error messages get merged even though `p1` succeeded. The somewhat counterintuitive reason is that parsers can return nonempty error message lists even when they don't fail. For example, a parser that skips over the *optional* string `"str"` will return `Reply(Ok, (), expectedString "str")` if it doesn't find the string in the input. In this case the error message describes what further input the parser could have parsed at the current stream position. If subsequently a parser fails at the same position, all error messages for the same position can be aggregated to give the user as much information as possible about what went wrong and what alternative inputs could have been parsed at the given position.

The following sample demonstrates the helpful effect of this error handling behaviour:
``
let str s = pstring s

let oneOrTwoInts =
    str "(" >>. tuple2 pint32 (opt (str "," >>. spaces >>. pint32)) .>> str ")"
``
``{fsi}
> run oneOrTwoInts "(1 2)";;
val it : ParserResult<(int32 * int32 option),unit> = Failure:
Error in Ln: 1 Col: 3
(1 2)
  ^
Expecting: ')' or ','
``
This error message wouldn't mention the possibility of a missing comma if the `.>>` combinator did not merge error messages for the same position when the left-hand side parser succeeds.

[/section]

[section The `StateTag`]

Parser combinators often need to check whether a parser has changed the `CharStream` state. In a typical FParsec application these checks are performed so frequently that an efficient implementation is important for the overall parser performance. Since a straightforward comparison of the complete `CharStream` states can be quite expensive, the `CharStream` class provides a shortcut for this purpose: the `StateTag`.

The `StateTag` is a simple integer counter that is incremented every time a `CharStream` method changes the state. Thus, if the `StateTag` hasn't changed, you can safely infer that the state hasn't changed either.[fn Of course, this doesn't apply if you manually set back the `StateTag` to the old value. There is also the purely theoretical possibility that the `StateTag` has overflown and was incremented exactly 2[sup 64] times (or 2[sup 32] if you define the `SMALL_STATETAG` conditional compiler symbol).] Except for some special cases, the opposite is also true: if the `StateTag` has changed, the state has changed too.

In the following special cases checking whether the `StateTag` has changed is not equivalent to checking whether the `CharStream` state has changed, because the tag may change even though the state doesn't:
- A parser calls the basic `Skip` or `Read` methods with a 0 offset or an empty argument string.
- A parser seeks the `CharStream` to the current position or replaces the user state with the current value.
- A parser makes several calls to `CharStream` methods and in later calls undoes the changes it made in earlier calls.

The first and second cases only have practical relevance for generic or parameterized parsers and can be simply avoided by checking the arguments before calling the respective `CharStream` methods. The third case only arises in the context of backtracking and it too can be easily avoided, either by using the `BacktrackTo` method for backtracking or by manually restoring the `StateTag` after the backtracking.

In practice these special cases are extremely rare, usually without consequences for the parser behaviour and always easily avoidable. Hence, FParsec combinators make free use of the `StateTag` to check whether a parser has changed the `CharStream` state.

[/section]

[section Generalizing `>>.`]

The parsers `p1 .>> p2` and `p1 >>. p2` only return the results of `p1` and `p2` respectively. If you want to combine the results from both `p1` and `p2`, you could use the `pipe2` combinator instead:
``val pipe2: Parser<'a,'u> -> Parser<'b,'u> -> ('a -> 'b -> 'c) -> Parser<'c,'u>``

The parser `pipe2 p1 p2 f` will apply `p1` and `p2` in sequence, exactly like `>>.`, but instead of returning one of the result values of `p1` and `p2` it will return the result of the function application `f x1 x2`, where `x1` and `x2` are the results returned by `p1` and `p2`.

There are also `pipe3`, `pipe4` and `pipe5` combinators, in case you need more than two arguments. Often these combinators are used to pass arguments to object constructors, like in the following example of a parser for a comma-separated list of XYZ coordinates:
``
type Data = Point of float*float*float

let ws = spaces
let str s = pstring s .>> ws
let number = pfloat .>> ws
let point = pipe3 number (str "," >>. number) (str "," >>. number)
                  (fun x y z -> Point(x, y, z))
``
``{fsi}
> run point "1, 2, 3";;
val it : ParserResult<Data,unit> = Success: Point (1.0,2.0,3.0)
``

If you just want to return the parsed values as a tuple, you can use the predefined `tuple2-5` parsers. For example, `tuple2 p1 p2` is equivalent to `pipe2 p1 p2 (fun x1 x2 -> (x1, x2)`.

`tuple2` is also available under the operator name `.>>.`, so that you can write `p1 .>>. p2` instead of `tuple2 p1 p2`.

There is no `pipe1` combinator, but there is an operator for the same purpose:
``
val (|>>): Parser<'a,'u> -> ('a -> 'b) -> Parser<'b, 'u>
``

This operator is used similarly to the F#'s ubiquitous pipeline operator `|>`:
``
type Expression = Number of int
                | Identifier of string

let number = pint32 |>> Number
``
``{fsi}
> run number "123";;
val it : ParserResult<Expression,unit> = Success: Number 123
``
[/section]

[section The `>>=` combinator]

All the sequencing and piping combinators we have discussed so far could be implemented with the help of the "bind" combinator:
``val (>>=): Parser<'a,'u> -> ('a -> Parser<'b,'u>) -> Parser<'b,'u>``

Instead of two parsers this combinator takes a parser and a *function producing a parser* as arguments. The combined parser `p >>= f` first applies the parser `p` to the input, then it applies the function `f` to the result returned by `p` and finally it applies the parser returned by `f` to the input. If we knew in advance that `p` returns `x` then `p >>= f` would be equivalent to `p >>. (f x)`.

The `>>=` combinator is quite versatile. For example, the following code
implements five of the previously discussed combinators in terms of `>>=` and the trivial `preturn` primitive:

``
let preturn x = fun stream -> Reply(x)

let (|>>) p  f    = p  >>= fun x -> preturn (f x)
let (.>>) p1 p2   = p1 >>= fun x -> p2 >>= fun _ -> preturn x
let (>>.) p1 p2   = p1 >>= fun _ -> p2 >>= fun y -> preturn y
let (.>>.) p1 p2  = p1 >>= fun x -> p2 >>= fun y -> preturn (x, y)
let pipe2 p1 p2 f = p1 >>= fun x -> p2 >>= fun y -> preturn (f x y)
``

In typical FParsec code `>>=` is only seldomly used, because in many situations where `>>=` could in principle be used one of the other specialized operators is more convenient to use and faster. However, on a conceptual level this combinator is important, because its generality allows us to define and test many combinators through their equivalence with a parser defined in terms of `>>=`.
This combinator is also significant for the role it plays in the monadic parser construction syntax, see [^where-is-the-monad].

[/section]

[/section]

[section Parsing sequences]

In the previous chapter we discussed various ways to sequentially apply two or more parsers. In this section we will explain how to repeatedly apply the same parser in order to parse a sequence with an arbitrary number of elements.

[section The `many` parser]
In regular expressions and many grammar formalisms a [url "http://en.wikipedia.org/wiki/Kleene_star" Kleene Star] marks a parser rule that can be repeatedly applied. For example, `number*` could represent a sequence of zero or more numbers.

In FParsec the `many` combinator takes the place of the Kleene Star:
``val many: Parser<'a,'u> -> Parser<'a list, 'u>``

With `many` the number example could be translated into the following FParsec code:
``
let ws = spaces
let number = pint32 .>> ws
``
``{fsi}
> run (many number) "1 2 3 4";;
val it : ParserResult<int32 list,unit> = Success: [1; 2; 3; 4]
``

The parser `many p` repeatedly applies the parser `p` until `p` fails, i.e. it "greedily" parses as many occurrences of `p` as possible. The results of `p` are returned as a list in the order of occurrence.

At the end of a sequence parsed with `many p` the argument parser `p` must fail without consuming input (or changing the parser state in any other way). When `p` fails after consuming input, `many p` fails with the error returned by `p`.

The following example illustrates this behaviour:

``
let ws = spaces
let str s = pstring s
let numberInBrackets = str "[" >>. pint32 .>> str "]" .>> ws
``

The `many numberInBrackets` parser successfully parses the first two numbers in this test run:
``{fsi}
> run (many numberInBrackets .>> str "(c)") "[1] [2] (c)";;
val it : ParserResult<int32 list,unit> = Success: [1; 2]
``

However, the same parser fails while trying to parse the 3rd number in this test run:
``{fsi}
> run (many numberInBrackets >>. str "[c]") "[1] [2] [c]";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 10
[1] [2] [c]
         ^
Expecting: integer number (32-bit, signed)
``

The `many` parser failed here because the `numberInBrackets` parser failed *after consuming input*. In the chapter on @looking ahead and backtracking@ we'll come back to this example and discuss how you can modify the `numberInBrackets` parser such that it fails without consuming input if an opening bracket is not followed by a number.[fn `many` doesn't automatically backtrack when the argument parser fails after changing the parser state for two reasons:
- In most situations automatic backtracking would only obscure error messages, because the reported input error was indeed severe and backtracking would only trigger secondary error messages that detract from the main error.
- In the few instances where you rely on backtracking behaviour you can easily introduce it using the combinators detailed in [^looking-ahead-and-backtracking]. Marking the occasions where you rely on backtracking with these combinators makes your parser implementations easier to debug and optimize.
]

Since `many p` continues until `p` fails, you have to be a little careful not to supply an argument parser `p` that can succeed without consuming input. The following example shows what happens if you accidentally supply such an argument parser:

``{fsi}
> run (many (many digit .>> ws)) "123 456";;
System.InvalidOperationException: (Ln: 1, Col: 8): The combinator 'many' was
applied to a parser that succeeds without consuming input and without changing
the parser state in any other way. (If no exception had been raised, the
combinator likely would have entered an infinite loop.)
   (... stack trace ...)
Stopped due to error
``

The problem here is that `many digit .>> ws` will succeed without changing the parser state if it can't parse any digits or trailing whitespace. Thus, if the combined parser hadn't have thrown an exception, it would have entered an infinite loop at the end of the input.

We can easily avoid the error in the last example by requiring the inner parser to consume at least one digit. Instead of `many digit`, which succeeds with an empty list if can't parse any digits, we can use `many1 digit`, which fails if it can't parse at least one digit:
``{fsi}
> run (many (many1 digit .>> ws)) "123 456";;
val it : ParserResult<char list list,unit> =
  Success: [['1'; '2'; '3']; ['4'; '5'; '6']]
``

Before we continue, we should point out that an example like `many1 digit` is somewhat artificial, because you hardly ever want to parse digit chars into a list. If you want to parse numbers, one of the [^parsing-numbers number parsers] is usually the best way forward. If you actually need the individual chars, you normally need them as a string, not as a list.

[tip
If you want to parse a sequence of chars, you should generally prefer one of the specialized [^parsing-strings-directly string parsers].
]

If you just want to skip over a sequence and don't need the list of parser results, you can  use the optimized combinators `skipMany` or `skipMany1`.

[/section]

[section `sepBy` and `sepEndBy`]

Often the elements of a sequence are separated by some separator. A convenient way to parse such sequences are the `sepBy` and `sepEndBy` combinators.

`sepBy p sep` parses a sequence of `p` separated by `sep` and returns the results in a list. `sepEndBy` parses a sequence of `p` separated *and optionally ended* by `sep`.

With these combinators you could for example define the following two parsers for a semicolon-separated list of numbers in brackets:
``
let str s = pstring s
let sepList    = between (str "[") (str "]") (sepBy    pint32 (str ";"))
let sepEndList = between (str "[") (str "]") (sepEndBy pint32 (str ";"))
``

The `sepList` parser only accepts lists where the semicolons only occur between two numbers:
``{fsi}
> run sepList "[]";;
val it : ParserResult<int32 list,unit> = Success: []
> run sepList "[1;2;3]";;
val it : ParserResult<int32 list,unit> = Success: [1; 2; 3]
> run sepList "[1;2;3;]";;
val it : ParserResult<int32 list,unit> = Failure:
Error in Ln: 1 Col: 8
[1;2;3;]
       ^
Expecting: integer number (32-bit, signed)
``

The `sepEndList` parser also accepts a terminating semicolon:
``{fsi}
> run sepEndList "[1;2;3]";;
val it : ParserResult<int32 list,unit> = Success: [1; 2; 3]
> run sepEndList "[1;2;3;]";;
val it : ParserResult<int32 list,unit> = Success: [1; 2; 3]
``

Like for the `many` combinator, there are also variants of the `sepBy` and `sepEndBy` parsers that require at least one element in the sequence and/or skip over a sequence without returning the results. Have a look at the [^parsing-sequences parser overview].

[/section]

[section Parsing a sequence without creating a list]

If you want to parse a sequence and you don't need the results as an F# list, you can avoid the allocation of a temporary list by defing a custom sequence parser using the inline helper methods `Inline.Many` and `Inline.SepBy`.

For example, if you wanted to define a variant of `many` that parses the elements directly into a `ResizeArray`, i.e. a `System.Collections.Generic.List`, you could use the following definition:

``
let manyRA p =
  // the compiler expands the call to Inline.Many to an optimized sequence parser
  Inline.Many(elementParser = p,
              stateFromFirstElement = (fun x0 ->
                                         let ra = ResizeArray<_>()
                                         ra.Add(x0)
                                         ra),
              foldState = (fun ra x -> ra.Add(x); ra),
              resultFromState = (fun ra -> ra),
              resultForEmptySequence = (fun () -> ResizeArray<_>()))
``

A test run:
``{fsi}
> run (manyRA (pint32 .>> spaces)) "1 2 3";;
val it : ParserResult<System.Collections.Generic.List<int32>,unit> =
  Success: seq [1; 2; 3]
``

The reference documentation for the `Inline` class contains some more examples.
[/section]

[/section]

[section Parsing alternatives]
FParsec's main operator for trying to parse input with alternative parsers is
``
val (<|>): Parser<'a,'u> -> Parser<'a,'u> -> Parser<'a,'u>
``

This operator implements a form of *prioritized choice*: it only tries to parse input with the second parser if the first parser fails.

The following example illustrates this behaviour:
``
type Char = AsciiChar of char
          | Char of char

let asciiLetter = asciiLetter |>> AsciiChar
let letter = letter |>> Char
``
``{fsi}
> run (asciiLetter <|> letter) "a";;
val it : ParserResult<Char,unit> = Success: AsciiChar 'a'
> run (letter <|> asciiLetter) "a";;
val it : ParserResult<Char,unit> = Success: Char 'a'
> run (asciiLetter <|> letter) "ä";;
val it : ParserResult<Char,unit> = Success: Char 'ä'
``

The prioritized choice also implies that FParsec doesn't enforce a longest-match rule like in regular expressions:
``{fsi}
> run (pstring "a" <|> pstring "ab") "ab";;
val it : ParserResult<string,unit> = Success: "a"
``

If you want to accept more than two alternatives, you can either chain multiple `<|>` operators, like in `p1 <|> p2 <|> p3`, or you can use the `choice` combinator, which accepts a sequence of parsers as the argument, like in `choice [p1; p2; p3]`. In both cases the argument parsers are tried from left to right until a parser succeeds.

A good understanding of the `<|>` operator is important for productively working with FParsec, so let's have a look at its implementation:

``
let (<|>) (p1: Parser<'a,'u>) (p2: Parser<'a,'u>) : Parser<'a,'u> =
    fun stream ->
        let stateTag = stream.StateTag
        let mutable reply = p1 stream
        if reply.Status = Error && stateTag = stream.StateTag then
            let error1 = reply.[^RError Error]
            reply <- p2 stream
            if stateTag = stream.StateTag then
                reply.[^RError Error] <- mergeErrors reply.[^RError Error] error1
        reply
``

As you can see, the parser `p1 <|> p2` works as follows: First, it applies the parser `p1` to the input stream. If `p1` succeeds, the reply of `p1` is returned. If `p1` fails with a non-fatal error (i.e. with the status `Error`, not `FatalError`) and *without changing the parser state*, the parser `p2` is applied. If `p2` does not change the parser state, the error messages from both parsers are merged. (We compare the `StateTag` values instead of the actual parser states for optimization reasons, see [^applying-parsers-in-sequence.the-statetag].)


The most important point to note here is that `p1 <|> p2` will always return with the reply of `p1` if `p1` changes the parser state, even if `p1` eventually fails. Remember that the stream position is part of the parser state, so if `p1` fails after consuming input, `p2` will not be applied. Since a parser usually consumes input as soon as it can accept at least one atomic token from the input, this means that `p1 <|> p2` by default implements backtracking with only a "one token look-ahead".

Consider the following example:
``
let parserA = spaces >>. pstring "a"
let parserB = spaces >>. pstring "b"
run (parserA <|> parserB) " b";;
``
``{fsi}
> run (parserA <|> parserB) " b";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 2
 b
 ^
Expecting: 'a'
``

The combined parser fails because `parserA` fails after consuming the whitespace, so that `parserB` never gets tried.

Of course, this simple parser could be easily fixed by factoring out the common prefix:
``{fsi}
> run (spaces >>. (pstring "a" <|> pstring "b")) " b";;
val it : ParserResult<string,unit> = Success: "b"
``

The restriction of the look-ahead in `p1 <|> p2` may strike you as odd at first, but it has two big advantages:
1) The error reporting is simplified and error messages are easier to understand because terminal errors can only occur at one position at a time.
2) Parser developers are guided towards more efficient grammar implementations because parsers requiring more than a one token look-ahead need to be explicitly annotated with the `attempt` or `>>?` combinators (see the [^looking-ahead-and-backtracking next chapter]).[fn In case you're wondering: No, we're not trying to sell a design limitation as a feature here. In Parsec, the Haskell library on which FParsec's design was originally based, the limited look-ahead is essential for the library design, because it allows Parsec to exploit Haskell's laziness in order to ensure space efficiency. FParsec has a different implementation in which the limited look-ahead has [^block-wise no effect on space efficiency]. We stick to the limited look-ahead because we think it's the appropriate default behaviour for a parser combinator library like FParsec. Now, admittedly, if FParsec could automatically optimize the implementation of a parser in a way that minimized backtracking, e.g. by automatically left-factoring grammars, then backtracking would be less of a problem and a different default behaviour might become more attractive.]

[/section]

[section Looking ahead and backtracking]

[section Backtracking]
Sometimes you need more than the default one token look-ahead of `<|>`, either because it really can't be avoided or because avoiding it would be too inconvenient. In those instances you can use one of the combinators `attempt`, `>>?`, `.>>?` or `>>=?` to force a parser to backtrack after an error.

The `attempt` combinator
``
val attempt: Parser<'a,'u> -> Parser<'a,'u>
``
takes a parser as the argument and returns a wrapped parser that behaves exactly like the argument, except that if the argument parser fails with an output state different from the input state or with a fatal error, the wrapped parser will backtrack to the original input state and report a non-fatal error.

You can observe the effect of the `attempt` combinator in the following error message:
``{fsi}
> run (attempt (pstring "a" >>. pstring "b")) "ac";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 1
ac
^

The parser backtracked after:
  Error in Ln: 1 Col: 2
  ac
   ^
  Expecting: 'b'
``

The next example demonstrates the effect of `attempt` on the choice combinator.

``
let str s = pstring s
let ab = str "a" .>>. str "b"
let ac = str "a" .>>. str "c"
``

Without `attempt` the following test produces an error:
``{fsi}
> run (ab <|> ac) "ac";;
val it : ParserResult<(string * string),unit> = Failure:
Error in Ln: 1 Col: 2
ac
 ^
Expecting: 'b'
``

By introducing `attempt` we allow the `<|>` combinator to recover from the error in the first branch:
``{fsi}
> run ((attempt ab) <|> ac) "ac";;
val it : ParserResult<(string * string),unit> = Success: ("a", "c")
``

Sometimes it can be a disadvantage that `attempt` will trigger backtracking after any error returned by the argument parser, no matter how much content the parser has consumed. Consider for example a parser like `prefix >>. expr`, where `expr` is a parser for a potentially large and deeply nested expression. If you wrap this parser with `attempt` then the wrapped parser will not only backtrack if an error occurs within the prefix or directly after the prefix, but also if it occurs anywhere in the expression. However, in most cases you only want the parser to backtrack if the error occurs directly after the prefix, not if the error occurs deeply inside the expression parser. For situations like this FParsec defines the `>>?`, `.>>?`, `.>>.?` and `>>=?` operators.

The `>>?` combinator
``
val (>>?):  Parser<'a,'u> -> Parser<'b,'u> -> Parser<'b,'u>
``
behaves like the `>>.` operator, except that `p1 >>? p2` will backtrack to the beginning if `p2` fails with a non-fatal error and without changing the parser state, even if `p1` has changed the parser state. Similarly, `.>>?`, `.>>.?` and `>>=?` behave like `.>>`, `.>>.` and `>>=`, except that they will backtrack to the beginning if the second parser fails with a non-fatal error and without changing the parser state

The following tests illustrate the differences between backtracking implemented via `attempt` and `.>>.?`.

``
let bInBrackets = str "[" >>. str "b" .>> str "]"
``

A test with `attempt` on the left side of `<|>`:
``{fsi}
> run ((attempt (str "a" .>>. bInBrackets)) <|> ac) "a[B]";;
val it : ParserResult<(string * string),unit> = Failure:
Error in Ln: 1 Col: 2
a[B]
 ^
Expecting: 'c'
``

A test with `attempt` on both sides of `<|>`:
``{fsi}
> run ((attempt (str "a" .>>. bInBrackets)) <|> attempt ac) "a[B]";;
val it : ParserResult<(string * string),unit> = Failure:
Error in Ln: 1 Col: 1
a[B]
^

The parser backtracked after:
  Error in Ln: 1 Col: 2
  a[B]
   ^
  Expecting: 'c'

The parser backtracked after:
  Error in Ln: 1 Col: 3
  a[B]
    ^
  Expecting: 'b'
``

A test with `.>>.?` instead of `attempt` on the left side of `<|>`:
``{fsi}
> run (str "a" .>>.? bInBrackets <|> ac) "a[B]";;
val it : ParserResult<(string * string),unit> = Failure:
Error in Ln: 1 Col: 3
a[B]
  ^
Expecting: 'b'
``

You can of course chain multiple of the `>>?` and `.>>?` operators to backtrack longer distances, like in `prefix1 >>? prefix2 >>? p .>>? postfix`.

[note
When implementing backtracking parsers you should generally prefer the `>>?`, `.>>?` and `.>>.?` combinators to the `attempt` combinator, because the former combinators offer finer control over the exact backtracking behaviour and hence will often lead to better error reporting. Note however that neither can completely replace the other.
]

Backtracking combinators can also be useful when parsing sequences. In the chapter "Parsing sequences" we briefly discussed the following example:

``
let ws = spaces
let str s = pstring s
let numberInBrackets = str "[" >>. pint32 .>> str "]" .>> ws
``
``{fsi}
> run (many numberInBrackets >>. str "[c]") "[1] [2] [c]";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 10
[1] [2] [c]
         ^
Expecting: integer number (32-bit, signed)
``

The problem here is that the argument parser to `many` fails after consuming input if it encounters a bracket that is not followed by a digit. If we decided that this is a defect of the parser as opposed to the grammar, we could fix it by simply replacing a `>>.` with `>>?`.

``
let numberInBrackets = str "[" >>? pint32 .>> str "]" .>> ws
``
``{fsi}
> run (many numberInBrackets .>> str "[c]") "[1] [2] [c]";;
val it : ParserResult<int32 list,unit> = Success: [1; 2]
``

A similar example is the `sepEndBy1` combinator for parsing a sequence of one or more elements separated and optionally ended by a separator. If FParsec didn't provide this combinator, you could define it yourself using `many` and `>>?`:
``
let sepEndBy1_ p sep =
    pipe2 p (many (sep >>? p)) (fun hd tl -> hd::tl) .>> opt sep
``

The following tests show that our `sepEndBy1` replacement works as expected:
``{fsi}
> run (sepEndBy1_ pint32 (str ";")) "1;2;3";;
val it : ParserResult<int32 list,unit> = Success: [1; 2; 3]
> run (sepEndBy1_ pint32 (str ";")) "1;2;3;";;
val it : ParserResult<int32 list,unit> = Success: [1; 2; 3]
``

Note however that in contrast to `sepEndBy1_` the version of `sepEndBy1` provided by FParsec doesn't need to parse the separator twice when it terminates a sequence.

[/section]
[section Parser predicates]

The backtracking combinators allow you to "look ahead" by tentatively parsing input and then backtracking if an error occurs. However, they don't allow you to conditionally parse the input with one parser depending on the success or failure of another parser. This is what the following two combinators are for:

``
val followedBy:    Parser<'a,'u> -> Parser<unit,'u>
val notFollowedBy: Parser<'a,'u> -> Parser<unit,'u>
``

The parser `followedBy p` (`notFollowedBy p`) succeeds *without changing the parser state* if `p` succeeds (fails) when applied at the current position.

For example, both the following parser definitions only parse positive integer literals without a leeding zero:
``
let p1 = followedBy    (satisfy ((<>) '0')) >>. pint32
let p2 = notFollowedBy (pstring "0")        >>. pint32
``

Both definitions will correctly parse `"123"` and fail to parse `"01"`:
``{fsi}
> run p1 "123";;
val it : ParserResult<int32,unit> = Success: 123
> run p1 "01";;
val it : ParserResult<int32,unit> =  Failure:
Error in Ln: 1 Col: 1
01
^
Unknown Error(s)
> run p2 "123";;
val it : ParserResult<int32,unit> = Success: 123
> run p2 "01";;
val it : ParserResult<int32,unit> = Failure:
Error in Ln: 1 Col: 1
01
^
Unknown Error(s)
``

While both parsers work as expected, the generated error messages aren't very helpful. The problem is that `followedBy` and `notFollowedBy` can't generate better error messages, because they don't know what kind of input their argument parsers accept.[fn In the case of `notFollowedBy p` the problem is clear: `notFollowedBy p` fails if `p` succeeds and when `p` succeeds, `p` doesn't generate an error message that `notFollowedBy` could reuse. In the case of `followedBy p` the situation is different: `followedBy p` fails if `p` fails, so `followedBy` could try to reuse the error messages generated by `p`. However, the error messages generated by the argument parser will in practice often not suffice to explain what kind of input is expected. So, for reasons of consistency and performance, `followedBy` doesn't even try to reuse the error messages generated by the argument parser.]
To improve the error messages you can either use the "labeled" combinator variants `followedByL` and `notFollowedByL` or you could use the labelling operator `<?>` that we will discuss in the next chapter.

For example:

``
> run (followedByL (satisfy ((<>) '0')) "positive int w/o leading 0" >>. pint32)
      "01";;
val it : ParserResult<int32,unit> =  Failure:
Error in Ln: 1 Col: 1
01
^
Expecting: positive int w/o leading 0

> run (followedBy (satisfy ((<>) '0')) >>. pint32 <?> "positive int w/o leading 0")
      "01";;
val it : ParserResult<int32,unit> = Failure:
Error in Ln: 1 Col: 1
01
^
Expecting: positive int w/o leading 0

> run (notFollowedByL (pstring "0") "'0'" >>. pint32) "01";;
val it : ParserResult<int32,unit> = Failure:
Error in Ln: 1 Col: 1
01
^
Unexpected: '0'
``

The parser `notFollowedByL (pstring "0") "'0'"` from the last example could actually be simplified to `notFollowedByString "0"`, which uses the specialized parser predicate `notFollowedByString`. In [^reference.parser-overview.conditional-parsing-and-looking-ahead] you'll find an overview of all available parser predicates.

A frequent application for the `notFollowedBy` predicate are sequence parsers similar to `many (notFollowedBy pEnd >>. p) .>> pEnd`. If you are writing such a parser, you should check whether you can replace it with an application of one of the [^manyTill-parsers `manyTill` parsers]. Please consult the reference for more details.

Before we conclude this chapter we want to emphasize that you're not limited to the built-in (backtracking) combinators of FParsec. A great advantage of FParsec is the simplicity with which you can write custom combinators using the low-level API.

For example, you could define a combinator that backtracks if the result of the argument parser doesn't satisfy a predicate function:

``
let resultSatisfies predicate msg (p: Parser<_,_>) : Parser<_,_> =
    let error = messageError msg
    fun stream ->
      let state = stream.State
      let reply = p stream
      if reply.Status <> Ok || predicate reply.Result then reply
      else
          stream.BacktrackTo(state) // backtrack to beginning
          Reply(Error, error)
``

With this combinator you could conveniently define a parser for positive ints:

``
let positiveInt = pint32 |> resultSatisfies (fun x -> x > 0)
                                            "The integer must be positive."
``
``{fsi}
> run positiveInt "1";;
val it : ParserResult<int32,unit> = Success: 1
> run positiveInt "-1";;
Error in Ln: 1 Col: 1
-1
^
The integer must be positive.
``

[/section]

[/section]

[section Customizing error messages]

Generating relevant and informative parser error messages is one of FParsec's greatest strengths. The top-down approach of recursive-descent parsing guarantees that there is always enough context to describe the exact cause of a parser error and how it could be avoided. FParsec exploits this context to automatically generate descriptive error messages whenever possible. This chapter explains how you can ensure with minimal efforts that your parser always produces understandable error messages.

As we already described in detail in [^applying-parsers-in-sequence.merging-error-messages], error reporting in FParsec is based on the following two principles:
- Parsers that fail or could have consumed more input return as part of their `Reply` an `ErrorMessageList` describing the input they expected or the reason they failed.
- Parser combinators aggregate all error messages that apply to the same input position and then propagate these error messages as appropriate.

The various error messages in the previous chapters demonstrate that the built-in error reporting usually works quite well even without any intervention by the parser author. However, sometimes FParsec lacks the information necessary to produce an informative error message by itself.

Consider for example the `many1Satisfy f` parser, which parses a string consisting of one or more chars satisfying the predicate function `f`. If this parser fails to parse at least one char, the generated error is not very helpful:
``{fsi}
> run (many1Satisfy isLetter) "123";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 1
123
^
Unknown Error(s)
``

The problem here is that `many1Satisfy` can't describe what chars the function predicate accepts. Hence, when you don't use `many1Satisfy` as part of a combined parser that takes care of a potential error, you better replace it with `many1SatisfyL`, which allows you to describe the accepted input with a label (hence the "L"):

``{fsi}
> run (many1SatisfyL isLetter "identifier") "123";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 1
123
^
Expecting: identifier
``

There are also labelled variants of other parsers and combinators, for example `choiceL` and `notFollowedByL`.

If there is no labelled parser variant or you want to replace a predefined error message, you can always use the labelling operator
``
val (<?>): Parser<'a,'u> -> string -> Parser<'a,'u>
``

The parser `p <?> label` behaves like `p`, except that the error messages are replaced with `expectedError label` if `p` does not change the parser state (usually because `p` failed).

For example, if FParsec didn't provide `many1SatisfyL`, you could define it yourself as
``
let many1SatisfyL f label = many1Satisfy f <?> label
``

The labelling operator is particularly useful for producing error messages in terms of higher-level grammar productions instead of error messages in terms of lower-level component parsers. Suppose you want to parse a string literal with the following parser
``
let literal_ = between (pstring "\"") (pstring "\"")
                       (manySatisfy ((<>) '"'))
``

If this parser encounters input that doesn't start with a double quote it will fail with the error message produced by the parser for the opening quote:
``{fsi}
> run literal_ "123";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 1
123
^
Expecting: '"'
``

In situations like these an error message that mentions the aggregate thing you're trying to parse will often be more helpful:
``
let literal = literal_ <?> "string literal in double quotes"
``
``{fsi}
> run literal "123";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 1
123
^
Expecting: string literal in double quotes
``

Note that `<?>` only replaces the error message if the parser doesn't consume input. For example, our `literal` parser won't mention that we're trying to parse a string literal if it fails after the initial double quote:
``{fsi}
> run literal "\"abc def";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 9
"abc def
        ^
Note: The error occurred at the end of the input stream.
Expecting: '"'
``

With the compound labelling operator `<??>` you can make sure that the compound gets mentioned even if the parser fails after consuming input:
``
let literal = literal_ <??> "string literal in double quotes"
``
``{fsi}
> run literal "\"abc def";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 1
"abc def
^
Expecting: string literal in double quotes

string literal in double quotes could not be parsed because:
  Error in Ln: 1 Col: 9
  "abc def
          ^
  Note: The error occurred at the end of the input stream.
  Expecting: '"'
``

[tip
If you don't like the formatting of these error messages, you can write a custom formatter for your application. The data structure in which error messages are stored is easy to query and process. See the reference for the [^FParsec..Error `Error` module].
]

The parsers we discussed so far in this chapter only generated `Expected` error messages, but FParsec also supports other type of error messages. For example, the `notFollowedByL` parser generates `Unexpected` error messages:
``{fsi}
> run (notFollowedByL spaces "whitespace") " ";;
val it : ParserResult<unit,unit> = Failure:
Error in Ln: 1 Col: 1

^
Unexpected: whitespace
``

Error messages that don't fit into the `Expected` and `Unexpected` categories can be produced with the `fail` and `failFatally` primitives:

``
let theory =
    charsTillString "3) " true System.Int32.MaxValue
     >>. (pstring "profit" <|> fail "So much about that theory ... ;-)")

let practice = "1) Write open source library 2) ??? 3) lot's of unpaid work"

``
``{fsi}
> run theory practice;;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 40
1) Write open source library 2) ??? 3) lot's of unpaid work
                                       ^
Expecting: 'profit'
Other error messages:
  So much about that theory... ;-)
``

If you can't get the built-in operators and parsers to produce the error message you need, you can always drop down one API level and write a special-purpose parser combinator.

The following example shows how you can define a custom `between` combinator that includes the position of the opening delimiter as part of the error message that gets generated when the closing delimiter cannot be parsed.

``
let betweenL (popen: Parser<_,_>) (pclose: Parser<_,_>) (p: Parser<_,_>) label =
  let expectedLabel = expected label
  let notClosedError (pos: Position) =
     messageError (sprintf "The %s opened at %s was not closed."
                           label (pos.ToString()))
  fun (stream: CharStream<_>) ->
    // The following code might look a bit complicated, but that's mainly
    // because we manually apply three parsers in sequence and have to merge
    // the errors when they refer to the same parser state.
    let state0 = stream.State
    let reply1 = popen stream
    if reply1.Status = Ok then
      let stateTag1 = stream.StateTag
      let reply2 = p stream
      let error2 = if stateTag1 <> stream.StateTag then reply2.[^RError Error]
                   else mergeErrors reply1.[^RError Error] reply2.[^RError Error]
      if reply2.Status = Ok then
        let stateTag2 = stream.StateTag
        let reply3 = pclose stream
        let error3 = if stateTag2 <> stream.StateTag then reply3.[^RError Error]
                     else mergeErrors error2 reply3.[^RError Error]
        if reply3.Status = Ok then
          Reply(Ok, reply2.Result, error3)
        else
          Reply(reply3.Status,
                mergeErrors error3 (notClosedError (state0.GetPosition(stream))))
      else
        Reply(reply2.Status, reply2.[^RError Error])
    else
      let error = if state0.Tag <> stream.StateTag then reply1.[^RError Error]
                  else expectedLabel
      Reply(reply1.Status, error)
``

The behaviour of the `betweenL` combinator differs from that of the standard `between` combinator in two ways:
- If `popen` fails without changing the parser state, `betweenL popen p pclose label` fails with `expected label`, just
  like `between popen p pclose <?> label` would have.
- If `pclose` fails without changing the parser state, `betweenL` additionally prints the opening position of the compound.

The following tests demonstrate this behaviour:

``
let stringLiteral = betweenL (str "\"") (str "\"")
                             (manySatisfy ((<>) '"'))
                             "string literal in double quotes"
``
``{fsi}
> run stringLiteral "\"test\"";;
val it : ParserResult<string,unit> = Success: "test"

> run stringLiteral "\"test";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 6
"test
     ^
Note: The error occurred at the end of the input stream.
Expecting: '"'
Other messages:
  The string literal in double quotes opened at (Ln: 1, Col: 1) was not closed.

> run stringLiteral "test";;
val it : ParserResult<string,unit> = Failure:
Error in Ln: 1 Col: 1
test
^
Expecting: string literal in double quotes
``

[/section]

[section Parsing with user state]

Each `[^CharStream_1 CharStream<'u>\ ]` holds a value of the freely definable user state type `'u`. In previous chapters we just ignored the user state and always assumed `'u` to be `unit`. In this section we finally get to discuss the purpose of the user state and how you can use it in your parsers.

[section Overview]
The user state allows you to introduce additional variables into the state tracked by FParsec parsers. It has the following two important properties:
- The user state is stored in the `[^CharStream_1 CharStream<'u>\ ]` instance and hence associated with the input. It is not shared globally and not associated with particular parser instances. The same parser instances can be concurrently applied to different `[^CharStream_1 CharStream<'u>\ ]` instances with different user state instances.
- The user state is tracked by FParsec parsers together with the input stream position. This means in particular that a parser restores the previous user state value when it backtracks.

[important
If you want changes to the user state to be undone during backtracking, you must change the user state by assigning a new value to the user state, not by mutating an existing user state value.
]

With the help of the user state you can implement context sensitive parsers, i.e. parsers whose behaviour not only depends on the immediate input but also on the context of the input. In general this works as follows:
# You establish a context by defining variables in the user state.
# You update the context depending on the input by letting parsers update the user state.
# You parse input depending on the context by making the parser behaviour dependent on the user state variables.

The user state is exposed through the `UserState` property of the `[^CharStream_1 CharStream<'u>\ ]`. You can implement parsers using the low-level API that directly access this property, or you can use the following parser primitives from the `CharParsers` module:
- `getUserState`,
- `setUserState`,
- `updateUserState`,
- `userStateSatisfies`.

The next section contains an example employing `updateUserState` to change the user state and `userStateSatisfies` to check for parser preconditions.

[/section]
[section Recursive grammars with nesting restrictions]

An important area of application for context sensitive parsers are recursive grammars where certain grammar elements cannot nest within others or where grammar elements need to be parsed differently depending on the nesting context.

Consider for example a textual markup languages like HTML. Many such markup languages support various "inline tags" to annotate text in a paragraph. Usually these inline tags can nest arbitrarily, except for a few tags with special restrictions. One of these restrictions often is that hyperlinks must not contain hyperlinks, even though they can contain any other inline content. Other restrictions may apply to elements allowed in superscript text or footnotes. A convenient way to enforce such restrictions during parsing is to introduce variables into the user state that keep track of the nesting context. The following example demonstrates this approach.[fn An alternative way to handle such restrictions at the parser level would be to define separate instances of the parser for each possible combination of restrictions, e.g. separate parsers for inline elements at the top level, for inline elements within hyperlinks, for elements within hyperlinks within superscript text and so on. However, with an increasing number of restrictions this approach quickly falls victim to the combinatorial explosion caused by the recursive nature of the involved parsers.]

The following parser for a tiny markup-language employs the user state
# to ensure that nested hyperlinks are not accepted and
# to parse potentially nested quotations between matching pairs of `'\''` or `'\"'` chars.

``
open FParsec

type Element = Text of string
             | Bold of Element list
             | Italic of Element list
             | Url of string * Element list
             | Quote of char * Element list

type UserState =
    {InLink: bool
     QuoteStack: char list}
    with
       static member Default = {InLink = false; QuoteStack = []}

let ws    = spaces
let ws1   = spaces1
let str s = pstring s

let elements, elementsR = createParserForwardedToRef()

let text = many1Satisfy (isNoneOf "<>'\"\\") |>> Text
let escape = str "\\" >>. (anyChar |>> (string >> Text))

let quote (q: char) =
  let pq = str (string q)

  let pushQuote =
      updateUserState (fun us -> {us with QuoteStack = q::us.QuoteStack})

  let popQuote =
      updateUserState (fun us -> {us with QuoteStack = List.tail us.QuoteStack})

  let isNotInQuote =
      userStateSatisfies (fun us -> match us.QuoteStack with
                                    | c::_ when c = q -> false
                                    | _ -> true)

  isNotInQuote >>. between pq pq
                           (between pushQuote popQuote
                                    (elements |>> fun ps -> Quote(q, ps)))

// helper functions for defining tags

let tagOpenBegin tag =
    str ("<" + tag)
    >>? nextCharSatisfiesNot isLetter // make sure tag name is complete
    <?> "<" + tag + "> tag"

let tagOpen tag = tagOpenBegin tag >>. str ">"
let tagClose tag = str ("</" + tag + ">")

let tag t p f =
    between (tagOpen t) (tagClose t)
            (p |>> f)

let attributeValue =
    ws >>. str "=" >>. ws
    >>. between (str "\"") (str "\"")
                (manySatisfy (isNoneOf "\n\""))

let attribute s = str s >>. attributeValue

let nonNestedTag tag pAttributesAndClose pBody f
                 isInTag setInTag setNotInTag =
    tagOpenBegin tag
    >>. ((fun stream ->
            if not (isInTag stream.UserState) then
                stream.UserState <- setInTag stream.UserState
                Reply(())
            else // generate error at start of tag
                stream.Skip(-tag.Length - 1)
                Reply(FatalError,
                      messageError ("Nested <" + tag + "> tags are not allowed.")))
         >>. pipe2 pAttributesAndClose pBody f
             .>> (tagClose tag >>. updateUserState setNotInTag))

// the tags

let bold   = tag "b" elements Bold
let italic = tag "i" elements Italic

let url = nonNestedTag "a" (ws >>. attribute "href" .>> (ws >>. str ">"))
                       elements
                       (fun url phrases -> Url(url, phrases))
                       (fun us -> us.InLink)
                       (fun us -> {us with InLink = true})
                       (fun us -> {us with InLink = false})


let element = choice [text
                      escape
                      quote '\''
                      quote '\"'
                      bold
                      italic
                      url]

do elementsR:= many element

let document = elements .>> eof
``
``{fsi}

> runParserOnString document UserState.Default ""
    "A \"'text' with 'nested \"<b>quotes</b>\"'.\"";;
val it : ParserResult<Element list,UserState> = Success:
[Text "A ";
 Quote
   ('"',
    [Quote ('\'',[Text "text"]); Text " with ";
     Quote ('\'',[Text "nested "; Quote ('"',[Bold [Text "quotes"]])]); Text "."])]

> runParserOnString document UserState.Default ""
    @"<b>Text <i></i>with</b> <a href=""url"">'link' but no \<blink\></a>";;
val it : ParserResult<Element list,UserState> = Success:
[Bold [Text "Text "; Italic []; Text "with"]; Text " ";
 Url("url",
     [Quote ('\'',[Text "link"]); Text " but no "; Text "<"; Text "blink";
      Text ">"])]

> runParserOnString document UserState.Default ""
    "<a href=\"url\"><a href=\"nested\">test</a></a>";;
val it : ParserResult<Element list,UserState> = Failure:
Error in Ln: 1 Col: 15
<a href="url"><a href="nested">test</a></a>
              ^
Nested <a> tags are not allowed.
``

[/section]

[section Parameterizing a parser through the user state]

The user state is also a good place to store parser configuration data that is specific to a "parser job". For example, a compiler that processes multiple compilation units could put configuration data that is specific to the compilation unit, e.g. include paths, into the user state and then parse different compilation units with the same `Parser` instance, like in the following code:

``
type CompilationUnitAST = (* ... *)

type UserState = {
    IncludePaths = string list
    (* ... *)
}

let parser : Parser<CompilationUnitAST, UserState> = (* ... *)

let parseCompilationUnit file encoding includePaths (* ... *) =
    let initialUserState = {IncludePaths = includePaths; (* ... *)}
    runParserOnFile parser initialUserState file encoding
``
[/section]

[/section]

[section Where is the monad?]

If you have previously used Haskell's Parsec library or an early version of FParsec you're probably wondering by now where the "monadic syntax" has gone. There's also a chance that you've stumbled upon FParsec while searching for a "monadic parser library" for F#/.Net and you're now wondering whether FParsec actually is one.

To answer these questions right away: FParsec supports a monadic parser construction syntax, but this syntax is only an optional feature, not the foundation of the library design. FParsec doesn't use the monadic syntax internally and we no longer recommend using it for new parser projects when performance is a concern.

[section An example using the monadic syntax]

With the monadic syntax you can, for example, write a parser for a pair of floating-point numbers as follows:

``
open FParsec

let ws = spaces // whitespace parser

let str_ws str = parse {do! skipString str
                        do! ws
                        return ()}

let number_ws = parse {let! number = pfloat
                       do! ws
                       return number}

let pairOfNumbers = parse {do! str_ws "("
                           let! number1 = number_ws
                           let! number2 = number_ws
                           do! str_ws ")"
                           return (number1, number2)}
``

We'll explain how the F# compiler handles the `parse {...}` expressions in the next section. For now, just compare the previous implementation with the following one using the usual FParsec combinators:

``
open FParsec

let ws = spaces // whitespace parser

let str_ws str = skipString str >>. ws

let number_ws = pfloat .>> ws

let pairOfNumbers = between (str_ws "(") (str_ws ")")
                            (tuple2 number1 number2)
``

The latter implementation is obviously more concise, but -- at least for users without prior exposure to FParsec -- the first implementation is probably a bit more intuitive and self-explanatory. What makes the first implementation so intuitive is that the syntax of the `parse {...}` expressions is a) very close to what developers are used to from their normal work with F# and b) expressive enough that it obviates the need for many of FParsec's basic combinators. Unfortunately, the intuitiveness of the monadic syntax comes at the price of a large performance penalty.

[/section]

[section How the monadic syntax works]

To explain how the monadic syntax works, we need to take a look at how the F# compiler translates the `parse {...}` expressions.

The foundation for the monadic syntax is the `>>=` combinator introduced in [^applying-parsers-in-sequence.the-combinator]:
``val (>>=): Parser<'a,'u> -> ('a -> Parser<'b,'u>) -> Parser<'b>``

This operator takes a parser and a function returning a parser as arguments. The combined parser `p >>= f` first applies the parser `p` to the input, then it applies the function `f` to the result returned by `p` and finally it applies the parser returned by `f` to the input. As we exlained in [^applying-parsers-in-sequence.the-combinator], this way to combine parsers is powerful enough that we can express many other sequencing combinators in terms of `>>=` and `preturn`.

For example, we could implement the `pipe3` combinator for sequentially applying three parsers as follows:

``
let pipe3 p1 p2 p3 f =
    p1 >>= fun x1 ->
             p2 >>= fun x2 ->
                      p3 >>= fun x3 ->
                               preturn (f x1 x2 x3)
``

Directly using the `>>=` and `preturn` combinators obviously leads to somewhat unwieldy and unreadable expressions. Fortunately, F#'s @computation expressions@ allow us to rewrite this expression in a more intuitive way:

``
let pipe3 p1 p2 p3 f =
    parse {let! x1 = p1
           let! x2 = p2
           let! x3 = p3
           return f x1 x2 x3}
``

The `parse` object that we reference in this and other code snippets of this chapter is a so-called "builder" object for computation expressions. It is defined in FParsec's `Primitives` module. Using the methods of this object, the F# compiler translates the computation expression in the curly braces to the following equivalent expression:

``
let pipe3 p1 p2 p3 f =
    parse.Delay(fun () ->
      parse.Bind(p1, fun x1 ->
        parse.Bind(p2, fun x2 ->
          parse.Bind(p3, fun x3 ->
            parse.Return(f (x1 x2 x3))))))
``

When we replace the `parse` object method calls with the respective method bodies, we will see that this definition is equivalent to our original definition using `>>=` and `preturn`.

The `Bind`, `Return` and `Delay` methods of the `parse` object are defined as:
``
    member t.Bind(p, f) = p >>= f
    member t.Return(x) = preturn x
    member t.Delay(f:(unit -> Parser<'a,'u>)) = fun stream -> (f ()) stream
``

Substituting these method bodies into the previous expression yields an expression that is very similar to the original one (except for the additional indirection introduced by the `Delay` method[fn The computation expression specification does not require a `Delay` method.
So, we could avoid the overhead associated with the additional indirection by removing the `Delay` method from the `ParserCombinator` class. However, this would make the behaviour of `parse` expressions somewhat counter-intuitive, as the behaviour would differ from the behaviour of F#'s `seq` and `async` expressions.]):

``
let pipe3 p1 p2 p3 f =
    fun stream ->
      (p1 >>= fun x1 ->
                p2 >>= fun x2 ->
                         p3 >>= fun x3 ->
                                  preturn (f x1 x2 x3)) stream
``

In summary, the `parse {...}` syntax is syntactic sugar for defining parsers with the `>>=` operator. The expressiveness of this syntax stems from the power of the `>>=` operator.

[/section]

[section The term "monad"]

A function with a signature like the one of the `>>=` operator is often called "bind". The above examples make it obvious why: the `>>=` combinator binds the result of the parser on the left-hand side to the function argument on the right-hand side.

The `Parser` type together with the `>>=` and `preturn` operations constitute a @monad@, which is an abstraction in type theory that denotes this kind of combination of a generic type with associated bind and return operations.

Discussing the theoretical background of monads would be outside the scope of this user's guide. For our purposes it is enough to note that the monad abstraction is so useful for certain applications that F# comes with built-in syntax support for monadic expressions.  FParsec utilizes this language feature (@computation expressions@) to enable `parse {...}` expressions.

Be assured that you don't need to know anything about monads in general in order to use FParsec's `parse {...}` expressions. To fully understand this feature all you need to know to is how the F# compiler translates `parse {...}` expressions into normal code.

Besides `let!`, `do!` and `return` there are some more language constructs that are supported inside `parse {...}` expressions. Please refer to the [^reference.Primitives.members.parse reference documentation] for more information.
[/section]

[section Why the monadic syntax is slow]

Compared to parsers implemented with only the usual FParsec operators and functions, parsers implemented with `parse {...}` expressions can be up to several times slower.

The relatively bad performance can be directly attributed to the way `parse {...}` expressions are compiled. As you have seen above, a `parse {...}` expression is simply translated into a series of nested closures that are chained through calls to the `>>=` operator. *With the current compiler technology and the current implementation of FParsec* this introduces some significant overhead.

*Every time* a `Parser` function constructed with the `parse {...}` syntax is called:
- Two function closures get newly instantiated for each invocation of the `>>=` operator: the closure that is passed as the second argument to `>>=` and the closure that is returned by `>>=`.
- Any parser created inside a `parse {...}` expression gets (re-)created every time execution reaches that point in the expression.

In principle, you can avoid the overhead described in the second point by moving the construction of parser functions out of the `parse {...}` expression.

For example, you can avoid the repeated construction of the `skipString` parsers in
``
let numberInParens = parse {do! skipString "("
                            let! number = pfloat
                            do! skipString ")"
                            return number}
``
by rewriting the code as
``
let parenOpen = skipString "("
let parenClose = skipString ")"
let numberInParens = parse {do! parenOpen
                            let! number = pfloat
                            do! parenClose
                            return number}
``

However, if you wanted to factor out any parser construction from a `parse {...}` expression, you'd also have to factor out any use of parser combinators, which would take away a lot from the attractiveness of the syntax.

If performance is not that important for your application, you can just ignore that a parser like `skipString "("` is repeatedly constructed, since its construction is relatively cheap. But if you do the same for parsers based on `regex` or `anyOf`, where the construction potentially involves some relatively expensive compilation or runtime code generation, you might be surprised just how slow your parsers can become.

Because of the described performance issues, we recommend not to use `parse {...}` expressions and instead work with FParsec's rich set of operators and other combinators. Not only does the operator-based notation (which is used everywhere else in FParsec's documentation) lead to faster parsers, it also allows for more concise parser code with a higher signal-to-noise ratio.

[/section]

[/section]


[section Debugging a parser]

Debugging a parser implemented with the help of a combinator library has its special challenges. In particular, setting a breakpoint and stepping through the code is not as straightforward as in a regular recursive descent parser. Furthermore, stack traces can be difficult to decipher because of the ubiquitous use of anonymous functions.[fn Although, debugging a parser written with a combinator library is often still easier than debugging one generated by an opaque parser generator tool.] However, with the help of the techniques we explain in this chapter, working around these issues should be easy.

[section Setting a breakpoint]

Suppose you have a combined parser like
``let buggyParser = pipe2 parserA parserB (fun a b -> ...)``
and you would like to break into the debugger whenever `buggyParser` calls `parserB`. One thing you could try is to set a breakpoint at the beginning of `parserB`. However, that's only possible if `parserB` is not itself a combined parser, and even then you still have the problem that your breakpoint is also triggered whenever `parserB` is called from any other place in your source. Similarly, a breakpoint you set in `pipe2` will probably be triggered by many other parsers besides `buggyParser`.

Fortunately there's a simple workaround if you can modify and recompile the code. Just define a wrapper function like the following
``
let BP (p: Parser<_,_>) stream =
    p stream // set a breakpoint here
``

Then redefine the buggy parser as
``
let buggyParser = pipe2 parserA (BP parserB) (fun a b -> ...)
``

If you now set a breakpoint at the body of the BP function, it will be triggered whenever `parserB` is called from `buggyParser`.

With such a wrapper it's also easy define a precise conditional breakpoint. For example, if you only want to break once the parser has reached line 100 of the input file, you could use the breakpoint condition `stream.Line >= 100`.

By the way, you don't need to set the breakpoint in the debugger. You can also write it directly into the code:
``
let BP (p: Parser<_,_>) (stream: CharStream<_>) =
    // this will execute much faster than a
    // conditional breakpoint set in the debugger
    if stream.Line >= 100L then
        System.Diagnostics.Debugger.Break()
    p stream
``

[note
There are some issues with setting breakpoints in or stepping into anonymous or curried F# functions in Visual Studio 2008. In Visual Studio 2010 many of these issues have been fixed.

If you're using Visual Studio, don't forget to switch on the "Suppress JIT optimization on module load" option in the Tools -- Options -- Debugging -- General dialog. And, when possible, use a debug build (of FParsec) for debugging.
]

[/section]

[section Tracing a parser]
Occasionally you have a parser that doesn't work as expected and playing around with the input or staring at the code long enough just isn't enough for figuring out what's wrong. In such cases the best way to proceed usually is to trace the execution of the parser. Unfortunately, stepping through the parser under a debugger can be quite tedious, because it involves stepping through long sequences of nested invocations of parser combinators. A more convenient approach often is to output tracing information to the console or a logging service.

A simple helper function for printing trace information to the console could like the following example:
``
let (<!>) (p: Parser<_,_>) label : Parser<_,_> =
    fun stream ->
        printfn "%A: Entering %s" stream.Position label
        let reply = p stream
        printfn "%A: Leaving %s (%A)" stream.Position label reply.Status
        reply
``

To demonstrate how you could use such a tracing operator, let's try to debug
the following buggy (and completely silly) parser:

``
let number = many1Satisfy isDigit

let emptyElement = pstring "[]" : Parser<_,unit>
let numberElement = pstring "[" >>. number .>> pstring "]"
let nanElement = pstring "[NaN]"

let element = choice [emptyElement
                      numberElement
                      nanElement] .>> spaces

let elements : Parser<_,unit> = many element
``

The following test run shows that the above parser is indeed buggy:
``{fsi}
> run elements "[] [123] [NaN]";;
val it : ParserResult<string list,unit> = Failure:
Error in Ln: 1 Col: 11
[] [123] [NaN]
          ^
Unknown Error(s)
``

You probably don't need trace information to figure out why the `"NaN"` bit of the string doesn't get parsed, but let's pretend you do. Obviously, there's something wrong with the `element` parser. To find out what's wrong, let's decorate the `element` parser and all subparsers with the `<!>` operator and an appropriate label:

``
let number = many1Satisfy isDigit <!> "number"

let emptyElement  = pstring "[]"                           <!> "emptyElement"
let numberElement = pstring "[" >>. number .>> pstring "]" <!> "numberElement"
let nanElement    = pstring "[NaN]"                        <!> "nanElement"

let element = choice [emptyElement
                      numberElement
                      nanElement] .>> spaces <!> "element"

let elements  : Parser<_,unit> = many element
``

If you now run the parser on the same input as before, you get the following output:
``{fsi}
> run elements "[] [123] [NaN]";;
(Ln: 1, Col: 1): Entering element
(Ln: 1, Col: 1): Entering emptyElement
(Ln: 1, Col: 3): Leaving emptyElement (Ok)
(Ln: 1, Col: 4): Leaving element (Ok)
(Ln: 1, Col: 4): Entering element
(Ln: 1, Col: 4): Entering emptyElement
(Ln: 1, Col: 4): Leaving emptyElement (Error)
(Ln: 1, Col: 4): Entering numberElement
(Ln: 1, Col: 5): Entering number
(Ln: 1, Col: 8): Leaving number (Ok)
(Ln: 1, Col: 9): Leaving numberElement (Ok)
(Ln: 1, Col: 10): Leaving element (Ok)
(Ln: 1, Col: 10): Entering element
(Ln: 1, Col: 10): Entering emptyElement
(Ln: 1, Col: 10): Leaving emptyElement (Error)
(Ln: 1, Col: 10): Entering numberElement
(Ln: 1, Col: 11): Entering number
(Ln: 1, Col: 11): Leaving number (Error)
(Ln: 1, Col: 11): Leaving numberElement (Error)
(Ln: 1, Col: 11): Leaving element (Error)
val it : ParserResult<string list,unit> = Failure:
Error in Ln: 1 Col: 11
[] [123] [NaN]
          ^
Unknown Error(s)
``

This trace log clearly reveals that the `element` parser failed because the `numberElement` parser failed after consuming the left bracket and thus the `choice` parser never got to try the the `nanElement` parser. Of course, this issue could be easily avoided by factoring out the bracket parsers from the `emptyElement`, `numberElement` and `nanElement` parsers. Also, if we had used `many1SatisfyL` instead of `manySatisfy` for the `number` parser, we would have gotten an error message more descriptive than "Unknown error(s)" (see the chapter on @customizing error messages@).
[/section]

[/section]


[section Performance optimizations]

In the past, the relatively poor performance of parser combinator libraries has often been cited as the primary impediment to their more widespread adoption. For this reason optimal performance stood front and center as a design goal during the development of FParsec and a lot of effort has been spent on optimizing parsing speed. As a result, FParsec has become so fast that parsers implemented with FParsec often significantly outperform parsers created by parser generator tools like fslex & fsyacc.

In general, a parser implemented in FParsec can get close to the performance of a hand-optimized recursive-descent parser written in C#. Due to the multi-layered architecture of the FParsec API, you always have the option to fall back to the lower-level API should a particular parser component implemented with the high-level API turn out to be too slow. Hence, if you choose FParsec for implementing your parsers, you don't have to worry that performance will become a reason for switching away from FParsec.

[section Performance guidelines]

If you strive for optimal performance in your parser applications, try to adhere to the following guidelines:
[dl
[Avoid backtracking]
[
Try to avoid backtracking where possible. Sometimes it's already enough to factor out a common prefix from a parser expression to avoid backtracking, e.g. by  transforming `(prefix >>? p1) <|> (prefix >>? p2)` to `prefix >>. (p1 <|> p2)`. Some simple backtracking can also be avoided by parsing whitespace as trailing whitespace instead of leading whitespace.

If you're designing a programming or markup language, you should try to minimize the need for backtracking, both to simplify parsing and to avoid exponential worst-case behaviour.
]

[Prefer specialized parsers]
[
FParsec provides a number of specialized parsers and combinators for various purposes. Using more specialized primitives instead of reimplementing them with generic combinators will often safe you time and improve parsing speed.

In particular:
- Prefer the `skip...` variants of parsers and combinators if you don't need the parser results.
- Parse whitespace with the built-in whitespace parsers.
- Parse numbers with the built-in number parsers.
- Prefer to parse strings with the `many[1]Satisfy[2][L]` parsers.
- Consider parsing unicode identifiers with the `identifier` parser.
]

[[# Construct parsers once]]
[
Constructing a parser can be relatively expensive in comparison to a single invocation of the parser. Hence, if you repeatedly apply the same parser, you should make sure that you construct the parser only once, either by preconstructing it at the beginning or by lazily constructing the parser and then caching it.

Usually the place where parsers get inadvertently constructed more than once is inside closures.

For example, if you have a local function like
``
fun stream ->
    let reply = (parser1 >>. parser2) stream
    if reply.Status = Ok then // ...
    else // ...
``
you should avoid the repeated construction of `parser1 >>. parser2` every time the closure is called by moving the construction outside of the closure, as in
``
let parser = parser1 >>. parser2
fun stream ->
    let reply = parser stream
    if reply.Status = Ok then //...
    else // ...
``

Also, you shouldn't wrap a parser expression inside a function just to avoid F#'s value restriction if you can achieve the same goal with a type annotation. For example, you should **not** try to fix the compiler error in the first example of the [^fs-value-restriction tutorial chapter on F#'s value restriction] by replacing
``let p = pstring "test"``
with
``let p stream = pstring "test" stream``
]

[Avoid `parse {...}` expressions]
[
See @Why the monadic syntax is slow@.
]

[Avoid `regex` parsers]
[
The `regex` parser parses a string by applying a .NET regular expression to the input. Since .NET regular expressions are relatively slow, you should reserve the use of the `regex` parser for patterns that you can't easily express with other FParsec parsers and combinators.
]

[Consider optimizing large `choice` parsers]
[
Formal grammars for programming languages or DSLs often have one or two grammar rules at their core that essentially just enumerate a long list of possible ways to form a statement or expression in that language. A straightforward FParsec implementation of such a grammar rule typically uses the `choice` combinator to combine a list of parsers for all the alternatives.

Usually such an implementation with a large `choice`-based parser will do just fine. However, if parsing performance is critical for your application, replacing a large `choice` parser with a custom-made combinator can be an optimization with a high benefit-cost ratio. The next section explains this optimization in more detail.
]
]

[/section]

[section Low-level parser implementations]

FParsec's high-level API consists of its built-in parsers and combinators in the `Primitives` and `CharParsers` module. The high-level API allows you to easily construct parsers in a concise and rather declarative way. Usually you will author most of your parsers using the high-level API, because that's the most productive way to do it.

However, sometimes you might find that a specific piece of parser functionality is a bit inconvenient to express through the high-level API or that the high-level implementation isn't as fast as you had hoped for. In those situations it's a great advantage that FParsec allows you to drop down to the low-level API, so that you can implement your own special-purpose parser and combinator primitives.

We have already covered the basics of the low-level API in the chapters on the @internals of a simple parser function@ and [@ applying parsers in sequence]. In this section we will discuss some examples that demonstrate how you can use low-level parser implementations for optimization purposes.

One example of a parser implemented using the low-level API is contained in the samples folder of the FParsec distribution in [= samples/FSharpParsingSample/FParsecVersion/parser.fs]. It is a parser for an identifier string that is not identical with a keyword.

The low-level implementation uses another parser, `identifierString`, to parse an identifier string and then backtracks when the parsed string is a keyword:
``
let identifier : Parser<string, unit> =
    let expectedIdentifier = expected "identifier"
    fun stream ->
        let state = stream.State
        let reply = identifierString stream
        if reply.Status <> Ok || not (isKeyword reply.Result) then reply
        else // result is keyword, so backtrack to before the string
            stream.BacktrackTo(state)
            Reply(Error, expectedIdentifier)
``

The same parser could also be implemented with the high-level API:
``
let identifier =
    attempt (identifierString
             >>= fun str ->
                     if not (isKeyword str) then preturn str
                     else pzero) <?> "identifier"

``

The high-level version is a bit more concise, but whether it is also easier to understand is debatable. The low-level version seems at least a bit more self-explanatory and hence is probably more accessible to new FParsec users. Since the low-level implementation is also significantly faster than the high-level one, this is a good example for a parser that can be improved through a low-level implementation.

If you wanted to optimize the performance of the identifier parser even more, you could replace the `identifierString` parser invocation with direct calls to `CharStream` methods. However, whether the potential performance gain would be worth the loss in code modularity and maintainability is questionable. A more promising optimization often is to integrate the identifier parser into a higher-level `choice`-based parser, like it is done below in the last example of this section.

`choice` parsers with long list of argument parsers are performance-wise one of the weakest spots of FParsec's high-level API. As we noted in the previous section, formal grammars for programming languages or DSLs often have one or two grammar rules at their core that essentially just enumerate a long list of possible ways to form a statement or expression in that language. A straightforward implementation of such a grammar rule using the `choice` combinator yields only sub-optimal performance, since the `choice` parser has no knowledge about its argument parsers and has to try one parser after another.

This makes large `choice`-based parsers an excellent optimization opportunity. With your knowledge about the parser grammar you can often narrow down the set of possible parsers just by peeking at the following one or two chars in the input. Having identified the set of possible parsers (often only consisting of one parser), you can then considerably speed up the dispatch to the right subparser.

For example, take a look at the @JSON-value parser@ from the tutorial:
``
choice [jobject
        jlist
        jstring
        jnumber
        jtrue
        jfalse
        jnull]
``

If you look at the definitions for the argument parsers, you'll see that in almost all cases one can decide which parser should handle the input just based on the next char in the input.  Hence, we could replace the `choice`-based parser with the following low-level implementation:

``
let error = expected "JSON value"
fun (stream: CharStream<_>) ->
    match stream.Peek() with
    | '{' -> jobject stream
    | '[' -> jlist stream
    | '"' -> jstring stream
    | 't' when stream.Skip("true")  -> Reply(JBool true)
    | 'f' when stream.Skip("false") -> Reply(JBool false)
    | 'n' when stream.Skip("null")  -> Reply(JNull)
    | _ ->
        let stateTag = stream.StateTag
        let mutable reply = jnumber stream
        if reply.Status = Error && stateTag = stream.StateTag then
           reply.[^RError Error] <- error
        reply
``

A drawback of such a low-level implementation is that you have to be a bit careful not to overlook any of the possible grammar cases. This is why we applied the `jnumber` parser in the "catch-all" case, so that we don't depend on the precise grammar rules for numbers.

You also need to consider how the low-level implementation affects error messages. When a `choice` parser fails, it will generate an error message with the error messages from all the argument parsers it tried. This gives a human reader usually enough context to understand the error. For a low-level implementation it can take a little more effort to ensure that the error messages for every case contain enough information about the grammar context. For example, in our implementation above we had to replace the default error message by `jnumber` with a custom one, so that the error message generated by the catch-all case doesn't create the impression that a JSON value can only be a number.

By now it is probably obvious that a low-level parser implementation can actually be quite simple to write, but that it also comes at a certain cost in terms of code modularity and maintainability. Having the option of a low-level implementation can certainly be what saves a project in certain situations and should give you some peace of mind with regard to parser performance, but generally you should only consider it as a backup option for those cases where you really need it.

The following example shows again how you can replace a `choice`-based parser with a low-level implementation, this time with a  grammar that is a bit more representative of a typical programming language:

``
type Expr = Number float
          | LetBinding ...
          | IfThenElse ...
          | ...

type UserState = //...

type Parser<'result> = Parser<'result, UserState>

type Keyword = None = 0
             | If   = 1
             | Let  = 2
             // ...

let stringToKeyword = createStaticStringMapping
                          Keyword.None
                          ["if", Keyword.If
                           "let", Keyword.Let
                           // ...
                          ]

let str s = pstring s

let identifierString : Parser<string> = // ...

let identifierRest (id: string) : Parser<Expr> = ...

let number : Parser<Expr> = // ... (parser for floating-point number)

let ifThenElseRest   : Parser<Expr> = // ...
let letBindingRest   : Parser<Expr> = // ...
let exprInParensRest : Parser<Expr> = // ...

// The parser after this comment is a replacement for
//     let identifierStringButNoKeyword =
//         (* implementation like identifier parser in the first example above *)
//
//     let identifier   : Parser<Expr> = identifierStringButNoKeyword
//                                       >>= identifierRest
//
//     let ifThenElse   : Parser<Expr> = str "if"  >>. ifThenElseRest
//     let letBinding   : Parser<Expr> = str "let" >>. letBindingRest
//     let exprInParens : Parser<Expr> = str "("   >>. exprInParensRest
//
//     let expr = choice [identifierStringNoKeyword
//                        number
//                        ifThenElse
//                        exprInParens
//                        // ...
//                       ]
//
let expr : Parser<Expr> =
  fun stream ->
    let stateTag = stream.StateTag
    let reply = identifierString stream
    if reply.Status = Ok then
      match stringToKeyword reply.Result with
      | Keyword.None -> identifierRest reply.Result stream
      | Keyword.If   -> ifThenElseRest stream
      | Keyword.Let  -> letBindingRest stream
      // ...
    elif reply.Status = Error && stateTag = stream.StateTag then // no identifier
      match stream.Peek() with
      | '(' -> stream.Skip(); exprInParensRest stream
      | c when isDigit c -> number stream
      // ...
    else // error within identifier string
      Reply(reply.Status, reply.[^RError Error])

``

[/section]

[/section]

[section Tips and tricks]

[toc]

[section Parallel parsing]

If your parser grammar is suitable for parallel parsing, parallelizing the parser has the potential to dramatically accelerate parsing on multi-core machines. In the following we will shortly discuss requirements and strategies for parallelizing an FParsec parser.

For a parser grammar to be well suited for parallel parsing, the grammar and the typical input must satisfy the following two criteria:
- Parts of the input must be independently parseable, i.e. parts must be parseable without knowlege about the other parts.
- These parts must be large enough and easily enough identifiable within the total input.

Often, the easiest and most beneficial way to parallelize the parsing stage of an application is to parse multiple input files in parallel. In the simplest case you have multiple independent "compilation units" that can be parsed in parallel. This works even for C/C++, where a badly designed preprocesser generally makes efficient parsing quite hard. In many programming languages and markup languages you can also parse in parallel files that are "included", "opened" or "imported" within source files. However, this usually only works if the language allows such includes only at well-defined points in the grammar. In languages like C/C++, where the unstructured text content of other files can be included at essentially arbitrary positions in the source, parsing the included files in parallel is generally quite hard. (In C/C++ it's even hard to avoid parsing the same file multiple times when it is included multiple times).

If you're dealing with large input files or very slow parsers, it might also be worth trying to parse multiple sections within a single file in parallel. For this to be efficient there must be a fast way to find the start and end points of such sections. For example, if you are parsing a large serialized data structure, the format might allow you to easily skip over segments within the file, so that you can chop up the input into multiple independent parts that can be parsed in parallel. Another example could be a programming languages whose grammar makes it easy to skip over a complete class or function definition, e.g. by finding the closing brace or by interpreting the indentation. In this case it *might* be worth not to parse the definitions directly when they are encountered, but instead to skip over them, push their text content into a queue and then to process that queue in parallel.

Here are some tips for parallel parsing with FParsec:
- All FParsec parsers are thread-safe and can be safely applied concurrently to different `CharStream` instances, as long as you don't introduce mutable shared state yourself.
- `CharStream` instances are not thread-safe and a single instance must not be accessed concurrently.
- However, you can call the `CreateSubstream` method to create a substream for a `CharStream`. A `CharStream` and its substreams can be safely accessed concurrently.
- If you want to parse multiple files in parallel, you should also create the `CharStream` instances in parallel, because the `CharStream` constructors that accept file paths or binary streams perform I/O operations that benefit from parallelization.
- If you parallelize your parser, consider introducing an option for switching off parallel execution, since debugging a multi-threaded parser is harder than debugging a single-threaded one.

[/section]

[section Dispatching parsers through a dictionary]

A technique that is often useful for making a parser modular and easily extensible is to store `Parser` functions in dictionaries and then to delegate parsing to one of the `Parser` functions in the dictionary based on the input.

For example, a parser for a markup language could be implemented by defining a generic tag parser that delegates the parsing of the tagged content to a specific parser for the respective tag name. The following code shows how this could be done:

``
open FParsec
open System.Collections.Generic

// For simplicity we don't define a full-blown markup language here,
// just a parser for two simple non-recursive "tags" in square brackets.
// The chapter on "parsing with user state" contains a slightly more developed
// sample for a markup language, though without a dictionary-based tag parser.

type Tag = Bold of string
         | Url of string * string

// We store the tag parser dictionary in the user state, so that we can
// concurrently parse multiple input streams with the same parser instance
// but differerent tag dictionaries.

type TagParserMap = Dictionary<string,Parser<Tag,UserState>>

and UserState = {
        TagParsers: TagParserMap
     }

let defaultTagParsers = TagParserMap()

let isTagNameChar1 = fun c -> isLetter c || c = '_'
let isTagNameChar = fun c -> isTagNameChar1 c || isDigit c
let expectedTag = expected "tag starting with '['"

let tag : Parser<Tag, UserState> =
  fun stream ->
    if stream.Skip('[') then
        let name = stream.ReadCharsOrNewlinesWhile(isTagNameChar1, isTagNameChar,
                                                   false)
        if name.Length <> 0 then
            let mutable p = Unchecked.defaultof<_>
            if stream.UserState.TagParsers.TryGetValue(name, &p) then p stream
            else
                stream.Skip(-name.Length)
                Reply(Error, messageError ("unknown tag name '" + name + "'"))
        else Reply(Error, expected "tag name")
    else Reply(Error, expectedTag)

let str s = pstring s
let ws = spaces
let text = manySatisfy (function '['|']' -> false | _ -> true)

defaultTagParsers.Add("b", str "]" >>. text .>> str "[/b]" |>> Bold)

defaultTagParsers.Add("url",      (str "=" >>. manySatisfy ((<>)']') .>> str "]")
                             .>>. (text .>> str "[/url]")
                             |>> Url)

let parseTagString str =
    runParserOnString tag {TagParsers = TagParserMap(defaultTagParsers)} "" str

``
``{fsi}
> parseTagString "[b]bold text[/b]";;
val it : ParserResult<Tag,UserState> = Success: Bold "bold text"

> parseTagString "[url=http://tryfsharp.org]try F#[/url]";;
val it : ParserResult<Tag,UserState> =
  Success: Url ("http://tryfsharp.org","try F#")

> parseTagString "[bold]test[/bold]";;
val it : ParserResult<Tag,UserState> = Failure:
Error in Ln: 1 Col: 2
[bold]test[/bold]
 ^
unknown tag name 'bold'
``
[/section]

[section Memoizing parsers]

If your parser implementation backtracks a lot when parsing typical inputs and as a result repeatedly applies some `Parser` functions at the same input position, it can be beneficial to memoize these `Parser` functions, i.e. cache their results for each input position.

In the extreme case, [url "http://en.wikipedia.org/wiki/Memoization" memoization] can mean the difference between linear and exponential execution times. In practice, FParsec is typically used for formal grammars that hardly require any extensive backtracking, so that memoization would usually only have a negative affect on performance.

In situation where you really do need to memoize parsers, you can work with a generic `memoize` combinator like the one in the following example:

``
open FParsec
open System.Collections.Generic

// We need a place to store the cached parser results. Since we want parser
// instances to be able to concurrently access different caches for different
// input streams, we will use a user state variable for this purpose. Since we
// don't want the backtracking to undo changes to the cache,  we will use a
// mutable dictionary for this purpose.

type UserState = {
        MemoCache: Dictionary<MemoKey, obj>
        // ...
    }

// An entry in the MemoCache must be uniquely identified by its MemoKey. In this
// example the MemoKey includes the stream index value and a reference to the
// memoized parser instance. Should the result of a memoized Parser function in
// your implementation also depend on the UserState value, you will have to
// extend the MemoKey with a UserState member. Similarly, if you want to cache
// results for more than one stream in the MemoCache, you'll have to extend the
// MemoKey with an identifier for the stream.

and [<CustomEquality; NoComparison>]
    MemoKey = struct
        new (parser: obj, stream: CharStream) =
            {[no-auto-link Parser] = parser; [no-auto-link Index] = stream.Index}

        val [no-auto-link Parser]: obj
        val [no-auto-link Index]: int64

        interface System.IEquatable<MemoKey> with
            member t.Equals(other: MemoKey) =
                t.[no-auto-link Index] = other.[no-auto-link Index] && t.[no-auto-link Parser] = other.[no-auto-link Parser]

        override t.Equals(otherObj: obj) =
            match otherObj with
            | :? MemoKey as other ->
                t.[no-auto-link Index] = other.[no-auto-link Index] && t.[no-auto-link Parser] = other.[no-auto-link Parser]
            | _ -> false

        override t.GetHashCode() = int32 t.[no-auto-link Index]
end

/// Returns a memoized version of the argument parser
let memoize (p: Parser<'a,UserState>) : Parser<'a,UserState> =
    fun stream ->
        let key = MemoKey(p, stream)
        let memoCache = stream.UserState.MemoCache
        let mutable boxedReply = null
        if memoCache.TryGetValue(key, &boxedReply) then
            boxedReply :?> Reply<'a>
        else
            let reply = p stream
            memoCache.Add(key, box reply)
            reply
``

[/section]

[section Parsing F# infix operators]
F# supports user-definable infix operators whose precedence and associativity depend on the first chars of the operator name. For example, the [url "http://research.microsoft.com/en-us/um/cambridge/projects/fsharp/manual/spec.html#_Toc257733507" F# spec] states that operators that start with `*` are left-associative, while operators that start with `**` are right associative and have a higher precedence, so that `1*2*.3**4**.5` is parsed as `((1*2)*.(3**(4 **.5)))`.

Since the precedence and associativity rules are fixed, you can parse F# expressions with a static operator precedence grammar, i.e. without having to reconfigure the parser when a new operator is defined in the parsed source code. However, it's probably not immediately obvious how to do this with FParsec's `OperatorPrecedenceParser` class (OPP), since the OPP normally expects all possible operators to be (individually) specified before they are used.

The trick to supporting whole classes of operator names without having to reconfigure the OPP at run-time is to shift part of the operator parsing to the [^Operator after-string-parser], like in the following example:

``
open FParsec

type Expr = InfixOpExpr of string * Expr * Expr
          | Number of int

let ws  = spaces  // whitespace parser

let isSymbolicOperatorChar = isAnyOf "!%&*+-./<=>@^|~?"
let remainingOpChars_ws = manySatisfy isSymbolicOperatorChar .>> ws

let opp = new OperatorPrecedenceParser<Expr, string, unit>()
opp.TermParser <- pint32 .>> ws |>> Number

// a helper function for adding infix operators to opp
let addSymbolicInfixOperators prefix precedence associativity =
    let op = InfixOperator(prefix, remainingOpChars_ws,
                           precedence, associativity, (),
                           fun remOpChars expr1 expr2 ->
                               InfixOpExpr(prefix + remOpChars, expr1, expr2))
    opp.AddOperator(op)

// the operator definitions:
addSymbolicInfixOperators "*"  10 Associativity.Left
addSymbolicInfixOperators "**" 20 Associativity.Right
// ...

``
``{fsi}
> run opp.ExpressionParser "1*2*.3**4**.5";;
val it : ParserResult<Expr,unit> = Success
InfixOpExpr
  ("*.", InfixOpExpr ("*", Number 1, Number 2),
         InfixOpExpr ("**", Number 3, InfixOpExpr ("**.", Number 4, Number 5)))
``


If you use the after-string-parser in this manner for operators that can lead to operator conflicts in the input, e.g. non-associative operators, then you also need to replace the default `OperatorConflictErrorFormatter`, since otherwise the default formatter may print truncated operator names:

``
addSymbolicInfixOperators "<"  1 Associativity.None
``
``{fsi}
> run opp.ExpressionParser "1 <= 2 <=. 3";;
val it : ParserResult<Expr,unit> = Failure:
Error in Ln: 1 Col: 9
1 <= 2 <=. 3
        ^
The infix operator '<' (precedence: 1, non-associative) conflicts with the
infix operator '<' (precedence: 1, non-associative) on the same line at column 3.
``

An error formatter that prints the full operator names could look like the following:

``
opp.OperatorConflictErrorFormatter <-
  fun (pos1, op1, afterString1) (pos2, op2, afterString2) ->
    let msg = sprintf "The operator '%s' conflicts with the previous operator '%s' at %A."
                       (op2.String + afterString2)
                       (op1.String + afterString1) pos1
    messageError msg
``
``{fsi}
> run opp.ExpressionParser "1 <= 2 <=. 3";;
val it : ParserResult<Expr,unit> = Failure:
Error in Ln: 1 Col: 9
1 <= 2 <=. 3
        ^
The operator '<=.' conflicts with the previous operator '<=' at (Ln: 1, Col: 3).
``

[/section]

[/section]
[/section]

